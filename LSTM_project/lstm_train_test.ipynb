{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define all constants used in the process training and testing the model.**\n",
    "\n",
    "This should be the only field user has to modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the inside of a folder containing all audio files\n",
    "DATA_PATH = r\"C:/Users/swirs/Desktop/guiio_data/ASVspoof2021_DF_eval/flac\"\n",
    "\n",
    "# Path to the CSV file containing names of the flac files in the folder indicated by DATA_PATH constant\n",
    "# and information whether those files contain \"fake\" or \"real\" recording\n",
    "FAKE_OR_REAL_PATH = r\"fake_or_real.csv\"\n",
    "\n",
    "# How many audio files will be processed at once, before being fed to neural network\n",
    "# Pro tip: do not go overboard with this, or your RAM will burn :)\n",
    "# Must be divisible by 2!\n",
    "PROCESS_BATCH_SIZE = int(1000)\n",
    "\n",
    "# How many files will be proccessed for training in total\n",
    "# Must be divisible by 2!\n",
    "NUM_OF_FILES = int(10000)\n",
    "\n",
    "# Sampling rate of audio file\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "# How many seconds of recording will be processed\n",
    "# If recording is shorter, remaining data will be filled with zeros\n",
    "NUM_OF_SECONDS = 3\n",
    "\n",
    "# Number of batches that will be used for tests\n",
    "BATCHES_FOR_TESTS = 2\n",
    "\n",
    "# Fow how many iterations will a single filename_batch be fed to neural network\n",
    "EPOCHS = 100\n",
    "\n",
    "# Size of a batch fed at once to neural network\n",
    "# Can not be greater than half of PROCESS_BATCH_SIZE!\n",
    "TRAIN_BATCH_SIZE = int(25)\n",
    "\n",
    "# Name of file to which network will be saved\n",
    "MODEL_NAME = \"LSTM_NETWORK_5\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import all necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check whether constant values provided by user were correct**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_PATH):\n",
    "    raise ValueError(\"Path to folder containing FLAC files does not exist!\")\n",
    "\n",
    "try:\n",
    "    fake_or_real_df = pd.read_csv(FAKE_OR_REAL_PATH)\n",
    "except:\n",
    "    raise ValueError(\"Couldn't open CSV file with information about whether data is fake or real!\")\n",
    "\n",
    "fake_data = fake_or_real_df[fake_or_real_df.iloc[:, 1] == \"fake\"]\n",
    "real_data = fake_or_real_df[fake_or_real_df.iloc[:, 1] == \"real\"]\n",
    "print(\"Total number of fake files = {}\".format(len(fake_data)))\n",
    "print(\"Total number of real files = {}\".format(len(real_data)))\n",
    "\n",
    "if PROCESS_BATCH_SIZE % 2 != 0:\n",
    "    raise ValueError(\"FILE_BATCH_SIZE must be divisible by 2!\")\n",
    "\n",
    "if NUM_OF_FILES % 2 != 0:\n",
    "    raise ValueError(\"NUM_OF_FILES must be divisible by 2!\")\n",
    "\n",
    "if (NUM_OF_FILES / 2) >= len(real_data):\n",
    "    raise ValueError(\"Folder does not contain enough samples of real data! Pleace reduce the NUM_OF_FILES constant!\")\n",
    "\n",
    "if (NUM_OF_FILES / 2) >= len(fake_data):\n",
    "    raise ValueError(\"Folder does not contain enough samples of fake data! Pleace reduce the NUM_OF_FILES constant!\")\n",
    "\n",
    "if TRAIN_BATCH_SIZE > PROCESS_BATCH_SIZE / 2:\n",
    "    raise ValueError(\"TRAIN_BATCH_SIZE can not be greater than half of PROCESS_BATCH_SIZE!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select files with fake and real data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will be used to split dataframe\n",
    "def splitDataframe(df, batch_size=10000): \n",
    "    chunks = list()\n",
    "    num_chunks = int(np.ceil(len(df) / batch_size))\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*batch_size:(i+1)*batch_size])\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Chose indices and split them into batches\n",
    "real_idx_batches = splitDataframe(random.sample(list(real_data.index), NUM_OF_FILES // 2), PROCESS_BATCH_SIZE // 2)\n",
    "fake_idx_batches = splitDataframe(random.sample(list(fake_data.index), NUM_OF_FILES // 2), PROCESS_BATCH_SIZE // 2)\n",
    "\n",
    "# Get each batch of indices load filenames into list of pandas dataframes\n",
    "filename_batches = []\n",
    "for real_indices, fake_indices in zip(real_idx_batches, fake_idx_batches):\n",
    "    batch = pd.concat([fake_or_real_df.loc[real_indices], fake_or_real_df.loc[fake_indices]])\n",
    "    batch.reset_index(drop=True, inplace=True)       # So we have nice, monotonically increasing indices\n",
    "    batch.replace(\n",
    "        {\"fake_real\" : \n",
    "            {\n",
    "            \"fake\" : 0, \n",
    "             \"real\" : 1\n",
    "            }\n",
    "        }, inplace=True)                             # Replace string with values more recognisable by neural network \n",
    "    filename_batches.append(batch)\n",
    "train_batches = filename_batches[:-BATCHES_FOR_TESTS]\n",
    "test_batches = filename_batches[-BATCHES_FOR_TESTS:]\n",
    "\n",
    "print(\"Number of train batches = {}\".format(len(train_batches)))\n",
    "print(\"Number of test batches = {}\".format(len(test_batches)))\n",
    "print(\"Filenames in each batch:\")\n",
    "sum = 0\n",
    "for i, batch in enumerate(train_batches):\n",
    "    print(\"    - Batch {}, elements = {}\".format(i + 1, len(batch)))\n",
    "    sum += len(batch)\n",
    "print(\"Total number of files = {}\".format(sum))\n",
    "\n",
    "print(\"\\n\\nExample dataframe:\")\n",
    "print(train_batches[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save test batch to temp file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_PATH = os.path.join(os.getcwd(), \"temp\")\n",
    "os.makedirs(\"temp\", exist_ok=True)\n",
    "for i, batch in enumerate(test_batches):\n",
    "    batch.to_csv(os.path.join(TEMP_PATH, f\"temp_test_batch_{i}.csv\"), encoding=\"utf-8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define function that loads single FLAC file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFlacFile(filename, duration):\n",
    "    file_path = os.path.join(DATA_PATH, filename + \".flac\")\n",
    "\n",
    "    audio, _ = librosa.load(file_path, duration=duration, offset=0.5, sr=SAMPLING_RATE)\n",
    "\n",
    "    signal = np.zeros((int(duration * SAMPLING_RATE,)))\n",
    "    signal[:len(audio)] = audio\n",
    "    \n",
    "    return signal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define function that adds noise to single audio signal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constant used to normalize signals\n",
    "NORM_CONSTANT = 2.0 ** (16 - 1)\n",
    "\n",
    "\n",
    "def createNoisySignal(signal, augmented_num=2, snr_low=15, snr_high=30): \n",
    "    signal_len = len(signal)\n",
    "    \n",
    "    # Generate White Gaussian noise\n",
    "    noise = np.random.normal(size=(augmented_num, signal_len))\n",
    "    \n",
    "    # Normalize signal and noise\n",
    "    signal_norm = signal / NORM_CONSTANT\n",
    "    noise_norm = noise / NORM_CONSTANT\n",
    "    \n",
    "    # Compute signal and noise power\n",
    "    s_power = np.sum(signal_norm ** 2) / signal_len\n",
    "    n_power = np.sum(noise_norm ** 2, axis=1) / signal_len\n",
    "    \n",
    "    # Random SNR: Uniform [15, 30] in dB\n",
    "    target_snr = np.random.randint(snr_low, snr_high)\n",
    "    \n",
    "    # Compute K (covariance matrix) for each noise \n",
    "    K = np.sqrt((s_power / n_power) * 10 ** (- target_snr / 10))\n",
    "    K = np.ones((signal_len, augmented_num)) * K  \n",
    "    \n",
    "    # Generate noisy signal\n",
    "    return signal + K.T * noise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define function that generates MEL spectograms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMelSpectrogram(audio, sample_rate):\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio,\n",
    "        sr=sample_rate,\n",
    "        n_fft=1024,\n",
    "        win_length=512,\n",
    "        window=\"hamming\",\n",
    "        hop_length = 256,\n",
    "        n_mels=128,\n",
    "        fmax=sample_rate / 2)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define function that processes batch (or it's part) on a single thread**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test whether spectogram is created correctly\n",
    "# No try-except because errors thrown by default would give more info\n",
    "# signal = loadFlacFile(train_batches[0].iloc[0, 0], NUM_OF_SECONDS)\n",
    "# spectogram = getMelSpectrogram(signal, SAMPLING_RATE)\n",
    "# shape = spectogram.shape\n",
    "# print(\"Spectogram created successfully!\")\n",
    "# print(\"Shape of crated spectogram: \", shape)\n",
    "\n",
    "# Global variables to which data will be written\n",
    "X_data = []\n",
    "Y_data = []\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# Helper function\n",
    "def resetVariables(batch_len):\n",
    "    global X_data, Y_data\n",
    "    X_data = [np.zeros((1, 1)) for _ in range(3 * batch_len)]\n",
    "    Y_data = [0 for _ in range(3 * batch_len)]\n",
    "\n",
    "\n",
    "# Main processing function\n",
    "def processAudioData(payload):\n",
    "    global X_data, Y_data, scaler\n",
    "\n",
    "    for i, row in payload.iterrows():\n",
    "        # Process signal\n",
    "        signal = loadFlacFile(row.iloc[0], NUM_OF_SECONDS)\n",
    "        spectogram = getMelSpectrogram(signal, SAMPLING_RATE)\n",
    "        augmented_signal = createNoisySignal(signal)\n",
    "        augmented_spectogram = getMelSpectrogram(augmented_signal, SAMPLING_RATE)\n",
    "\n",
    "        # Write signal to array\n",
    "        X_data[3 * i] = scaler.fit_transform(spectogram)\n",
    "        Y_data[3 * i] = row.iloc[1]\n",
    "        X_data[3 * i + 1] = scaler.fit_transform(augmented_spectogram[0, :])\n",
    "        Y_data[3 * i + 1] = row.iloc[1]\n",
    "        X_data[3 * i + 2] = scaler.fit_transform(augmented_spectogram[1, :])\n",
    "        Y_data[3 * i + 2] = row.iloc[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.module = module\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.size()) <= 2:\n",
    "            return self.module(x)\n",
    "        # Squash samples and timesteps into a single axis\n",
    "        elif len(x.size()) == 3:\n",
    "            x_reshape = x.contiguous().view(-1, x.size(2))                          # (samples * timesteps, inp1)\n",
    "        elif len(x.size()) == 4:\n",
    "            x_reshape = x.contiguous().view(-1, x.size(2), x.size(3))               # (samples * timesteps, inp1, inp2)\n",
    "        else:\n",
    "            x_reshape = x.contiguous().view(-1, x.size(2), x.size(3),x.size(4))     # (samples * timesteps, inp1, inp2, inp3)\n",
    "            \n",
    "        y = self.module(x_reshape)\n",
    "        \n",
    "        # Reshape Y\n",
    "        if len(x.size()) == 3:\n",
    "            y = y.contiguous().view(x.size(0), -1, y.size(1))                       # (samples, timesteps, out1)\n",
    "        elif len(x.size()) == 4:\n",
    "            y = y.contiguous().view(x.size(0), -1, y.size(1), y.size(2))            # (samples, timesteps, out1,out2)\n",
    "        else:\n",
    "            y = y.contiguous().view(x.size(0), -1, y.size(1), y.size(2),y.size(3))  # (samples, timesteps, out1,out2, out3)\n",
    "        return y\n",
    "    \n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_types):\n",
    "        super().__init__()\n",
    "        # conv block\n",
    "        self.conv2Dblock = nn.Sequential(\n",
    "            # 1. conv block\n",
    "            TimeDistributed(nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1)),\n",
    "            TimeDistributed(nn.BatchNorm2d(16)),\n",
    "            TimeDistributed(nn.ReLU()),\n",
    "            TimeDistributed(nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "            TimeDistributed(nn.Dropout(p=0.4)),\n",
    "            # 2. conv block\n",
    "            TimeDistributed(nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1)),\n",
    "            TimeDistributed(nn.BatchNorm2d(32)),\n",
    "            TimeDistributed(nn.ReLU()),\n",
    "            TimeDistributed(nn.MaxPool2d(kernel_size=4, stride=4)),\n",
    "            TimeDistributed(nn.Dropout(p=0.4)),\n",
    "            # 3. conv block\n",
    "            TimeDistributed(nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1)),\n",
    "            TimeDistributed(nn.BatchNorm2d(64)),\n",
    "            TimeDistributed(nn.ReLU()),\n",
    "            TimeDistributed(nn.MaxPool2d(kernel_size=4, stride=4)),\n",
    "            TimeDistributed(nn.Dropout(p=0.4)),\n",
    "            # 4. conv block\n",
    "            TimeDistributed(nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1)),\n",
    "            TimeDistributed(nn.BatchNorm2d(128)),\n",
    "            TimeDistributed(nn.ReLU()),\n",
    "            TimeDistributed(nn.MaxPool2d(kernel_size=4, stride=4)),\n",
    "            TimeDistributed(nn.Dropout(p=0.4))\n",
    "        )\n",
    "        \n",
    "        # LSTM block\n",
    "        hidden_size = 64\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=hidden_size, bidirectional=False, batch_first=True) \n",
    "        self.dropout_lstm = nn.Dropout(p=0.3)\n",
    "        \n",
    "        # Linear softmax layer\n",
    "        self.out_linear = nn.Linear(hidden_size, num_types)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        conv_embedding = self.conv2Dblock(x)\n",
    "        conv_embedding = torch.flatten(conv_embedding, start_dim=2) # do not flatten batch dimension and time\n",
    "        lstm_embedding, (h,c) = self.lstm(conv_embedding)\n",
    "        lstm_embedding = self.dropout_lstm(lstm_embedding)\n",
    "        \n",
    "        # lstm_embedding (batch, time, hidden_size)\n",
    "        lstm_output = lstm_embedding[:,-1,:] \n",
    "        output_logits = self.out_linear(lstm_output)\n",
    "        output_softmax = nn.functional.softmax(output_logits, dim=1)\n",
    "        \n",
    "        return output_logits, output_softmax\n",
    "    \n",
    "    \n",
    "def lossFnc(predictions, targets):\n",
    "    return nn.CrossEntropyLoss()(input=predictions, target=targets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define functions used to train and validate neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTrainStep(model, loss_fnc, optimizer):\n",
    "    def trainStep(X,Y):\n",
    "        # Set model to train mode\n",
    "        model.train()\n",
    "        \n",
    "        # Forward pass\n",
    "        output_logits, output_softmax = model(X)\n",
    "        predictions = torch.argmax(output_softmax, dim=1)\n",
    "        accuracy = torch.sum(Y == predictions) / float(len(Y))\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fnc(output_logits, Y)\n",
    "        \n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters and zero gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        return loss.item(), accuracy * 100\n",
    "    \n",
    "    # Return function handle\n",
    "    return trainStep\n",
    "\n",
    "\n",
    "def makeValidateFnc(model,loss_fnc):\n",
    "    def validate(X,Y):\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            output_logits, output_softmax = model(X)\n",
    "            predictions = torch.argmax(output_softmax, dim=1)\n",
    "            accuracy = torch.sum(Y==predictions) / float(len(Y))\n",
    "            loss = loss_fnc(output_logits, Y)\n",
    "        \n",
    "        return loss.item(), accuracy * 100, predictions\n",
    "    \n",
    "    # Return function handle\n",
    "    return validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_batches):\n",
    "    print(\"\\nProcessing batch {} / {}:\".format(i + 1, len(train_batches)))\n",
    "    resetVariables(len(batch))\n",
    "    batch_len = len(batch)\n",
    "    # Generate spectograms\n",
    "    print(\"    - generating spectograms\")\n",
    "    processAudioData(batch)\n",
    "    X_data = np.array(X_data)\n",
    "    X_data = np.expand_dims(X_data, axis=(1, 2))\n",
    "    Y_data = np.array(Y_data)\n",
    "    DATASET_SIZE = X_data.shape[0]    \n",
    "    # Train section\n",
    "    print(\"    - training neural network\")\n",
    "    print(\"        [ \", end=\"\")\n",
    "    # Mix data\n",
    "    with open(f'X_{i}.pkl','wb') as f:\n",
    "        pkl.dump(X_data, f)\n",
    "    with open(f'Y_{i}.pkl','wb') as f:\n",
    "        pkl.dump(Y_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(test_batches):\n",
    "    print(\"\\nProcessing batch {} / {}:\".format(i + 1, len(test_batches)))\n",
    "    resetVariables(len(batch))\n",
    "    batch_len = len(batch)\n",
    "    # Generate spectograms\n",
    "    print(\"    - generating spectograms\")\n",
    "    processAudioData(batch)\n",
    "    X_data = np.array(X_data)\n",
    "    X_data = np.expand_dims(X_data, axis=(1, 2))\n",
    "    Y_data = np.array(Y_data)\n",
    "    DATASET_SIZE = X_data.shape[0]    \n",
    "    # Train section\n",
    "    print(\"    - training neural network\")\n",
    "    print(\"        [ \", end=\"\")\n",
    "    # Mix data\n",
    "    with open(f'Xtest_{i}.pkl','wb') as f:\n",
    "        pkl.dump(X_data, f)\n",
    "    with open(f'Ytest_{i}.pkl','wb') as f:\n",
    "        pkl.dump(Y_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper handles/variables\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Selected device is {}'.format(device))\n",
    "\n",
    "model = HybridModel(num_types=2).to(device)\n",
    "print('Number of trainable params: {}'.format(np.sum([p.numel() for p in model.parameters()])))\n",
    "\n",
    "OPTIMIZER = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-3, momentum=0.8)\n",
    "\n",
    "train_step = makeTrainStep(model, lossFnc, optimizer=OPTIMIZER)\n",
    "validate = makeValidateFnc(model, lossFnc)\n",
    "loss_lst = []\n",
    "acc_lst = []\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Processing epoch {} / {}:\".format(epoch+1, EPOCHS))\n",
    "    for i, batch in enumerate(train_batches):\n",
    "        resetVariables(len(batch))\n",
    "        batch_len = len(batch)\n",
    "        # Generate spectograms\n",
    "        print(\"    - generating spectograms\")\n",
    "        with open(f'X_{i}.pkl','rb') as f:\n",
    "            X_data = pkl.load(f)\n",
    "        with open(f'Y_{i}.pkl','rb') as f:\n",
    "            Y_data = pkl.load(f)\n",
    "            \n",
    "        DATASET_SIZE = X_data.shape[0]    \n",
    "        # Train section\n",
    "        # print(\"    - training neural network\")\n",
    "        # print(\"        [ \", end=\"\")\n",
    "        # Mix data\n",
    "        ind = np.random.permutation(DATASET_SIZE)\n",
    "        X_data = X_data[ind,:,:,:,:]\n",
    "        Y_data = Y_data[ind]\n",
    "        \n",
    "        # Separate X_train and Y_train data into train batches\n",
    "        epoch_acc = 0\n",
    "        epoch_loss = 0\n",
    "        loss_acc_list = []\n",
    "        iters = int(DATASET_SIZE / TRAIN_BATCH_SIZE)\n",
    "        for j in range(iters):\n",
    "            # Calculate train batch range\n",
    "            batch_start = j * TRAIN_BATCH_SIZE\n",
    "            batch_end = min(batch_start + TRAIN_BATCH_SIZE, DATASET_SIZE)\n",
    "            actual_batch_size = batch_end-batch_start\n",
    "\n",
    "            # Get X and Y data\n",
    "            X = X_data[batch_start:batch_end,:,:,:,:]\n",
    "            Y = Y_data[batch_start:batch_end]\n",
    "\n",
    "            # Feed to neural network\n",
    "            X_tensor = torch.tensor(X, device=device).float()\n",
    "            Y_tensor = torch.tensor(Y, dtype=torch.long, device=device)\n",
    "            loss, acc = train_step(X_tensor,Y_tensor)\n",
    "\n",
    "            # Calculate accuracy and loss\n",
    "            epoch_acc += acc * actual_batch_size / DATASET_SIZE\n",
    "            epoch_loss += loss * actual_batch_size / DATASET_SIZE\n",
    "            loss_acc_list.append((epoch_loss,epoch_acc))\n",
    "            acc_lst.append(epoch_acc)\n",
    "            loss_lst.append(epoch_loss)\n",
    "\n",
    "        print('''Batch {}/{}  loss, acc: {}'''.format(i+1, len(train_batches), loss_acc_list), end=\"\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "# Save neural network\n",
    "SAVE_PATH = os.path.join(os.getcwd(), \"models\")\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "torch.save(model.state_dict(), os.path.join(SAVE_PATH, MODEL_NAME + \".pt\"))\n",
    "joblib.dump(scaler, os.path.join(SAVE_PATH, MODEL_NAME + \".save\"))\n",
    "print(\"Model was saved to {}\".format(os.path.join(SAVE_PATH, MODEL_NAME + \".pt\")))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main test loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "LOAD_PATH = os.path.join(os.getcwd(),\"models\")\n",
    "model = HybridModel(2)\n",
    "model.load_state_dict(torch.load(os.path.join(LOAD_PATH, MODEL_NAME + \".pt\")))\n",
    "print('Model is loaded from {}'.format(os.path.join(LOAD_PATH, MODEL_NAME + \".pt\")))\n",
    "\n",
    "# Reload needed variables\n",
    "device = 'cpu'\n",
    "print('Selected device is {}'.format(device))\n",
    "OPTIMIZER = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-3, momentum=0.8)\n",
    "train_step = makeTrainStep(model, lossFnc, optimizer=OPTIMIZER)\n",
    "validate = makeValidateFnc(model, lossFnc)\n",
    "\n",
    "# Load original batches\n",
    "TEMP_PATH = os.path.join(os.getcwd(), \"temp\")\n",
    "batches_backup = os.listdir(TEMP_PATH)\n",
    "\n",
    "test_batches = []\n",
    "for backup in batches_backup:\n",
    "    test_batches.append(pd.read_csv(os.path.join(TEMP_PATH, backup), index_col=0))\n",
    "\n",
    "for batch in test_batches:\n",
    "    print(batch)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(test_batches):\n",
    "    print(\"\\nProcessing batch {} / {}:\".format(i + 1, len(test_batches)))\n",
    "    resetVariables(len(batch))\n",
    "    batch_len = len(batch)\n",
    "\n",
    "    # Generate spectograms\n",
    "    print(\"    - generating spectograms\")\n",
    "    with open(f'Xtest_{i}.pkl','rb') as f:\n",
    "        X_data = pkl.load(f)\n",
    "    with open(f'Ytest_{i}.pkl','rb') as f:\n",
    "        Y_data = pkl.load(f)\n",
    "    # Test network\n",
    "    \n",
    "    X_test_tensor = torch.tensor(X_data, device=device).float()\n",
    "    Y_test_tensor = torch.tensor(Y_data, dtype=torch.long, device=device)\n",
    "    test_loss, test_acc, predictions = validate(X_test_tensor,Y_test_tensor)\n",
    "\n",
    "    # Print results\n",
    "    print(\"        * test loss is {:.3f}\".format(test_loss))\n",
    "    print(\"        * test accuracy is {:.2f}%\".format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
