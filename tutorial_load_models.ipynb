{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial do wczytywania modeli\n",
    "\n",
    "Poniżej są biblioteki, które zostały użyte do trenowania modelu. Raczej pasuje je mieć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2ddf73beef0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import lightning.pytorch as pl\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej jest kilka parametrów, tylkoo niektóre są użyte do zdefiniowania modelu, ale skopiowałem wszystkie z oryginalnego pliku, bo jestem leniwy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 128\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 128\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 32\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparameter for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Żeby wczytać model konieczne jest odtworzenie jego struktury, ZANIM się go wczyta. Stąd też potrzeba powyższych parametrów. Nwm czy metoda forward jest potrzebna, obstawiam że tak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 128 x 128\n",
    "            nn.Conv2d(nc, ndf, 4, stride=2, padding=1, bias=False), \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 64 x 64\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 32 x 32\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 16 x 16 \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 8 x 8\n",
    "            nn.Conv2d(ndf * 8, ndf * 16, 4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*16) x 4 x 4\n",
    "            nn.Conv2d(ndf * 16, 1, 4, stride=1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "            # state size. 1\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej wczytanie modelu z pliku. Wywołanie .eval() jest obowiązkowe (jakieś tam pierdolenie z batch normalization i dropoutami, nwm nie znam się)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (14): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (15): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netD = torch.load('discriminator_true.pth',map_location=torch.device('cpu'))\n",
    "netD.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzenie folderów real i fake\n",
    "Do data_path dodaj ścieżkę do folderu z plikami .flac <br>\n",
    "Skrypt spakuje te spektrogramy do folderów: reals oraz fakes na podstawie pliku CSV ASVspoof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get real/fake key from CSV\n",
    "data_key = pd.read_csv('spoof_data.csv')\n",
    "data_real_ID_list = data_key[data_key['spoof_bonafide']=='bonafide']\n",
    "data_fake_ID_list = data_key[data_key['spoof_bonafide']=='spoof']\n",
    "\n",
    "# split data to seperate folders containing fakes and reals and combined data\n",
    "data_path = '../spectrograms/real_noise/'\n",
    "data_reals_path = os.path.join(data_path,'reals')\n",
    "data_fakes_path = os.path.join(data_path,'fakes')\n",
    "if not os.path.exists(data_reals_path):\n",
    "    os.makedirs(data_reals_path)\n",
    "if not os.path.exists(data_fakes_path):\n",
    "    os.makedirs(data_fakes_path)\n",
    "\n",
    "if len(os.listdir(data_reals_path)) == 0:\n",
    "    for filename in os.listdir(data_path):\n",
    "        file_path = os.path.join(data_path, filename)\n",
    "\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(file_path):\n",
    "\n",
    "            filename = filename[:-4]\n",
    "            # check if file is fake or real\n",
    "            if(filename in data_real_ID_list['recording_ID'].values):\n",
    "                shutil.move(file_path, data_reals_path)\n",
    "            elif(filename in data_fake_ID_list['recording_ID'].values):\n",
    "                shutil.move(file_path, data_fakes_path)\n",
    "            else:\n",
    "                print(f'No file with name {filename} found in key database!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzenie datasetów mixed, real oraz fake\n",
    "tworzymy jeden dataset ze wszystkimi obrazami i dodatkowe dwa subsety z real'ami i fake'ami. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mixed dataset\n",
    "dataset_mixed = dset.ImageFolder(root=data_path,\n",
    "                                transform=transforms.Compose([\n",
    "                                transforms.Resize(image_size),\n",
    "                                transforms.CenterCrop(image_size),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# Create the mixed dataloader\n",
    "dataloader_mixed = torch.utils.data.DataLoader(dataset_mixed, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "\n",
    "# Create fake/real subsets\n",
    "list_of_real_idx = []\n",
    "list_of_fake_idx = []\n",
    "\n",
    "for num,(file_path, idx) in enumerate(dataset_mixed.imgs):\n",
    "    dir_path = file_path[:-17]\n",
    "    if(dir_path == data_reals_path):\n",
    "        list_of_real_idx.append(num)\n",
    "    elif(dir_path == data_fakes_path):\n",
    "        list_of_fake_idx.append(num)\n",
    "    else:\n",
    "        print('Invalid data!')\n",
    "\n",
    "subset_real = torch.utils.data.Subset(dataset=dataset_mixed, indices=list_of_real_idx)\n",
    "# Create the reals dataloader\n",
    "dataloader_reals = torch.utils.data.DataLoader(dataset=subset_real, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "\n",
    "subset_fake = torch.utils.data.Subset(dataset=dataset_mixed, indices=list_of_fake_idx)\n",
    "# Create the fakes dataloader\n",
    "dataloader_fakes = torch.utils.data.DataLoader(dataset=subset_fake, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ewaluacja modelu dla danych mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 3275 / 3406 with accuracy 96.15\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in dataloader_mixed:\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "        \n",
    "        scores = netD(x)\n",
    "        _, predictions = scores.max(1)\n",
    "        num_samples += predictions.size(0)\n",
    "        num_correct += (torch.squeeze(predictions) == y).sum()\n",
    "    \n",
    "    print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ewaluacja modelu dla danych real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 0 / 131 with accuracy 0.00\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in dataloader_reals:\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "        \n",
    "        scores = netD(x)\n",
    "        _, predictions = scores.max(1)\n",
    "        num_samples += predictions.size(0)\n",
    "        num_correct += (torch.squeeze(predictions) == y).sum()\n",
    "    \n",
    "    print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ewaluacja modelu dla danych fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 3275 / 3275 with accuracy 100.00\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in dataloader_fakes:\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "        \n",
    "        scores = netD(x)\n",
    "        _, predictions = scores.max(1)\n",
    "        num_samples += predictions.size(0)\n",
    "        num_correct += (torch.squeeze(predictions) == y).sum()\n",
    "    \n",
    "    print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
